import torch
import torch.nn as nn
import torch.nn.functional as F
import copy
import imageio
import os, os.path
import numpy as np


#nb_training_A = len([name for name in os.listdir('./trainA')])
#nb_training_B = len([name for name in os.listdir('./trainB')])
                    


def construction_images_tensor(name_dir):
    images = []
    for name in os.listdir(name_dir):
        #images.append(torch.transpose(torch.Tensor(imageio.imread('./trainA/' + name )), -1, 0))
        images.append(imageio.imread(name_dir + name ))
     
    images = np.array(images, dtype = float) / 255
    images = torch.as_tensor(images)
    images = torch.transpose(images, -1,1)
    print("fin du chargement des images de" + name_dir)
    return images

true_images_A = construction_images_tensor('./trainA/')
true_images_B = construction_images_tensor('./trainB/')
print(true_images_A.shape, true_images_B.shape)

#images = torch.transpose(images, -1, 1) 

#from PIL import Image
#im = Image.open('./trainA/00001.jpg')
#pixels = list(im.getdata())

RES_LAYER_NB = 5

class TransformOtherDimension(nn.Module):

    def __init__(self):
        super(TransformOtherDimension, self).__init__()
        self.downsampling1 = nn.Conv2d(3, 6, (7,7))
        self.downsampling2 = nn.Conv2d(6, 16, 3, stride = 2)
        self.res_layers = []
        
        for i in range(RES_LAYER_NB):
            tempo = []

            # All the layers in the res layer
            tempo.append(nn.Conv2d(16, 16, 3, padding = 1))
            tempo.append(nn.ReLU())
            tempo.append(nn.Conv2d(16, 16, 3, padding = 1))
            tempo.append(nn.ReLU())
            
            tempo.append(nn.ReLU()) # Used to add the input
            
            self.res_layers.append(tempo)

        self.upsampling1 = nn.ConvTranspose2d(16, 6, 7, stride = 1)
        self.upsampling2 = nn.ConvTranspose2d(6, 3, 3, stride = 2)

        

    def forward(self, x):
        x = self.downsampling1(x)
        print(x.shape)
        x = self.downsampling2(x)
        print(x.shape)

        for i in range(RES_LAYER_NB):
            tempo = torch.clone(x)
            x = self.res_layers[i][0](x)
            x = self.res_layers[i][1](x)
            x = self.res_layers[i][2](x)
            x = self.res_layers[i][3](x)
            
            x += tempo
            x = self.res_layers[i][4](x)
            print(x.shape)

        x = self.upsampling1(x)
        print(x.shape)
        x = self.upsampling2(x)
        print(x.shape)
        return x

class Discriminant(nn.Module):

    def __init__(self):
        super(Discriminant, self).__init__()

        self.downsampling1 = nn.Conv2d(3, 16, 3, stride = 2)
        self.downsampling2 = nn.Conv2d(16, 32, 3, stride = 2)
        self.downsampling3 = nn.Conv2d(32, 64, 3, stride = 1)
        self.downsampling4 = nn.Conv2d(64, 1, 3, stride = 1)

        

        

    def forward(self, x):
        x = self.downsampling1(x)
        x = self.downsampling2(x)
        x = self.downsampling3(x)
        x = self.downsampling4(x)
        return x

trans1 = TransformOtherDimension()
discr1 = Discriminant()

#input = torch.randn(20, 3, 50, 50)



