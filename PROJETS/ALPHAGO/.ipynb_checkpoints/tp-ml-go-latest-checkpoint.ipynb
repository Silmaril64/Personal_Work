{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-d8TGvJHm7l0"
   },
   "source": [
    "# Import du fichier d'exemples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1574,
     "status": "ok",
     "timestamp": 1607077337583,
     "user": {
      "displayName": "Silmaril",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj25vLnfeosorL9syqzgeWxPRhMcr90TgVY7lIv=s64",
      "userId": "13932754754043581055"
     },
     "user_tz": -60
    },
    "id": "JvbLprL7m7l3"
   },
   "outputs": [],
   "source": [
    "def get_raw_data_go():\n",
    "    ''' Returns the set of samples from the local file or download it if it does not exists'''\n",
    "    import gzip, os.path\n",
    "    import json\n",
    "\n",
    "    raw_samples_file = \"samples-9x9.json.gz\"\n",
    "\n",
    "    if not os.path.isfile(raw_samples_file):\n",
    "        print(\"File\", raw_samples_file, \"not found, I am downloading it...\", end=\"\")\n",
    "        import urllib.request \n",
    "        urllib.request.urlretrieve (\"https://www.labri.fr/perso/lsimon/ia-inge2/samples-9x9.json.gz\", raw_samples_file)\n",
    "        print(\" Done\")\n",
    "\n",
    "    with gzip.open(raw_samples_file) as fz:\n",
    "        data = json.loads(fz.read().decode(\"utf-8\"))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3273,
     "status": "ok",
     "timestamp": 1607077339294,
     "user": {
      "displayName": "Silmaril",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj25vLnfeosorL9syqzgeWxPRhMcr90TgVY7lIv=s64",
      "userId": "13932754754043581055"
     },
     "user_tz": -60
    },
    "id": "3K7GK4VuoQ-k",
    "outputId": "07ba1d12-c96b-429b-ca10-aab6296f4eb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 41563 examples\n"
     ]
    }
   ],
   "source": [
    "data = get_raw_data_go()\n",
    "print(\"We have\", len(data),\"examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0-2-MvFm7mS"
   },
   "source": [
    "# First steps: transform all the data into numpy arrays to feed your neural network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3272,
     "status": "ok",
     "timestamp": 1607077339297,
     "user": {
      "displayName": "Silmaril",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj25vLnfeosorL9syqzgeWxPRhMcr90TgVY7lIv=s64",
      "userId": "13932754754043581055"
     },
     "user_tz": -60
    },
    "id": "88tQeXmcm7mT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def name_to_coord(s):\n",
    "    assert s != \"PASS\"\n",
    "    indexLetters = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'H':7, 'J':8}\n",
    "\n",
    "    col = indexLetters[s[0]]\n",
    "    lin = int(s[1:]) - 1\n",
    "    return col, lin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hxgi08M1namb"
   },
   "source": [
    "To encode the board to be able to use it as an input vector to feed our neural network, we implemented three encoder:\n",
    "- one plane encoder: is a simple matrix (one plane) of board size where white stones are represented as -1, black stones as 1 and 0 if it's empty.\n",
    "- two plane encoder:  One plane for black and one plane for white, with a 1 if there is a black stone for the first plane and with a 1 if there is a white stone for the second plane, as you proposed in the notebook.\n",
    "- three plane encoder: is similar to the two plane encoder except that we have added the third plane which represent the next player considering that the next player has an advantage over the other player.\n",
    "\n",
    "After comparasion between the three encoder, we have noted that the third one leds to better performance in prediction so we chose to use it.\n",
    "\n",
    "To enrich our dataset with all symmetries and rotations, the encoder doesn't encode the original dataset only but also it generates all the symmetries by using numpy.rot90() and numpy.flipud()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3271,
     "status": "ok",
     "timestamp": 1607077339299,
     "user": {
      "displayName": "Silmaril",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj25vLnfeosorL9syqzgeWxPRhMcr90TgVY7lIv=s64",
      "userId": "13932754754043581055"
     },
     "user_tz": -60
    },
    "id": "dtMRkh1crZ2S"
   },
   "outputs": [],
   "source": [
    "def one_plane_encoder(data):\n",
    "  \"\"\"take as an input the json file and returns two arrays\n",
    "    the frist array is the board state and the second array \n",
    "    is the probabilities that black wins\n",
    "  \"\"\"\n",
    "  X = []\n",
    "  Y = []\n",
    "  for i in range(len(data)): \n",
    "      board = np.zeros((9,9), dtype=np.float32)\n",
    "      black = data[i][\"black_stones\"]\n",
    "      white = data[i][\"white_stones\"]\n",
    "      \n",
    "      for j in range(len(black)):\n",
    "          x,y = name_to_coord(black[j])\n",
    "          board[x,y] = 1\n",
    "      for j in range(len(white)):\n",
    "          x,y = name_to_coord(white[j])\n",
    "          board[x,y] = -1\n",
    "      X.append(board)\n",
    "      Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "      \n",
    "      X.append(np.rot90(board, k=1))\n",
    "      Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "      \n",
    "      X.append(np.rot90(board, k=2))\n",
    "      Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "      \n",
    "      X.append(np.rot90(board, k=3))\n",
    "      Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "      \n",
    "      board = np.flipud(board)\n",
    "      X.append(board)\n",
    "      Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "      \n",
    "      X.append(np.rot90(board, k=1))\n",
    "      Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "      \n",
    "      X.append(np.rot90(board, k=2))\n",
    "      Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "      \n",
    "      X.append(np.rot90(board, k=3))\n",
    "      Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "      \n",
    "  X_data = np.array(X)\n",
    "  Y_data = np.array(Y)\n",
    "  print(X_data.shape)\n",
    "  print(Y_data.shape)\n",
    "  return X_data, Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2943,
     "status": "ok",
     "timestamp": 1607077339301,
     "user": {
      "displayName": "Silmaril",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj25vLnfeosorL9syqzgeWxPRhMcr90TgVY7lIv=s64",
      "userId": "13932754754043581055"
     },
     "user_tz": -60
    },
    "id": "6zUJ59O6uY1g"
   },
   "outputs": [],
   "source": [
    "def two_planes_encoder(data):\n",
    "    \"\"\" take as an input the json file and returns two arrays\n",
    "    the frist array is the board state and the second array \n",
    "    is the probabilities that black wins\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(len(data)): \n",
    "        black_stones = np.zeros((9,9), dtype=np.float32)\n",
    "        white_stones = np.zeros((9,9), dtype=np.float32)\n",
    "        black = data[i][\"black_stones\"]\n",
    "        white = data[i][\"white_stones\"]\n",
    "        \n",
    "        for j in range(len(black)):\n",
    "            x,y = name_to_coord(black[j])\n",
    "            black_stones[x,y] = 1\n",
    "        for j in range(len(white)):\n",
    "            x,y = name_to_coord(white[j])\n",
    "            white_stones[x,y] = 1\n",
    "        img = np.dstack((black_stones,white_stones))\n",
    "        X.append(img)\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "        X.append(np.rot90(img, k=1, axes=(0,1)))\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "        X.append(np.rot90(img, k=2, axes=(0,1)))\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "        X.append(np.rot90(img, k=3, axes=(0,1)))\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "        img = np.flipud(img)\n",
    "        X.append(img)\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "        X.append(np.rot90(img, k=1, axes=(0,1)))\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "        X.append(np.rot90(img, k=2, axes=(0,1)))\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "        X.append(np.rot90(img, k=3, axes=(0,1)))\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "    X_data = np.array(X)\n",
    "    Y_data = np.array(Y)\n",
    "    print(X_data.shape)\n",
    "    print(Y_data.shape)\n",
    "    return X_data, Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1807,
     "status": "ok",
     "timestamp": 1607077341114,
     "user": {
      "displayName": "Silmaril",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj25vLnfeosorL9syqzgeWxPRhMcr90TgVY7lIv=s64",
      "userId": "13932754754043581055"
     },
     "user_tz": -60
    },
    "id": "IDePyXgywGem"
   },
   "outputs": [],
   "source": [
    "def three_planes_encoder(data):\n",
    "    \"\"\"take as an input the json file and returns two arrays\n",
    "    the frist array is the board state and the second array \n",
    "    is the probabilities that black wins\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(len(data)): \n",
    "        black_stones = np.zeros((9,9), dtype=np.float32)\n",
    "        white_stones = np.zeros((9,9), dtype=np.float32)\n",
    "        player_turn = np.zeros((9,9), dtype=np.float32)\n",
    "        black = data[i][\"black_stones\"]\n",
    "        white = data[i][\"white_stones\"]\n",
    "        \n",
    "        for j in range(len(black)):\n",
    "            x,y = name_to_coord(black[j])\n",
    "            black_stones[x,y] = 1\n",
    "        for j in range(len(white)):\n",
    "            x,y = name_to_coord(white[j])\n",
    "            white_stones[x,y] = 1\n",
    "        if (len(data[i][\"list_of_moves\"])%2 == 0):\n",
    "          # black turn 1, white turn 0\n",
    "          player_turn = np.ones((9,9), dtype=np.float32)\n",
    "        img = np.dstack((black_stones,white_stones,player_turn))\n",
    "        X.append(img)\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "        X.append(np.rot90(img, k=1, axes=(0,1)))\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "        X.append(np.rot90(img, k=2, axes=(0,1)))\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "        X.append(np.rot90(img, k=3, axes=(0,1)))\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "        img = np.flipud(img)\n",
    "        X.append(img)\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "        X.append(np.rot90(img, k=1, axes=(0,1)))\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "        X.append(np.rot90(img, k=2, axes=(0,1)))\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "        X.append(np.rot90(img, k=3, axes=(0,1)))\n",
    "        Y.append(data[i][\"black_wins\"]/data[i][\"rollouts\"])\n",
    "        \n",
    "    X_data = np.array(X)\n",
    "    Y_data = np.array(Y)\n",
    "    print(X_data.shape)\n",
    "    print(Y_data.shape)\n",
    "    return X_data, Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5844,
     "status": "ok",
     "timestamp": 1607077346836,
     "user": {
      "displayName": "Silmaril",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj25vLnfeosorL9syqzgeWxPRhMcr90TgVY7lIv=s64",
      "userId": "13932754754043581055"
     },
     "user_tz": -60
    },
    "id": "shgZz9cKsP04",
    "outputId": "601369f1-db34-4eed-f612-8b2090172a89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332504, 9, 9, 3)\n",
      "(332504,)\n",
      "(332504, 9, 9, 3)\n"
     ]
    }
   ],
   "source": [
    "X_data, Y_data = three_planes_encoder(data)\n",
    "print(X_data.shape)\n",
    "\n",
    "#np.savez('./dataset', X=X_data, Y=Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5435,
     "status": "ok",
     "timestamp": 1607077347890,
     "user": {
      "displayName": "Silmaril",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj25vLnfeosorL9syqzgeWxPRhMcr90TgVY7lIv=s64",
      "userId": "13932754754043581055"
     },
     "user_tz": -60
    },
    "id": "Xea6DzcR3upa",
    "outputId": "d5a9cc68-f47a-4f45-f004-347c36444cca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232752, 9, 9, 3)\n",
      "(99752, 9, 9, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.3)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "Y_train =Y_train.astype('float32')\n",
    "Y_test = Y_test.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "executionInfo": {
     "elapsed": 4356,
     "status": "ok",
     "timestamp": 1607077347893,
     "user": {
      "displayName": "Silmaril",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj25vLnfeosorL9syqzgeWxPRhMcr90TgVY7lIv=s64",
      "userId": "13932754754043581055"
     },
     "user_tz": -60
    },
    "id": "e5qj8KSf48j6",
    "outputId": "b108c92d-9788-43b1-99e5-ffcb67cb3f1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f887a735e50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELl2z3tbm7mX"
   },
   "source": [
    "# Second steps: build your neural network and train it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1582,
     "status": "ok",
     "timestamp": 1607077349620,
     "user": {
      "displayName": "Silmaril",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj25vLnfeosorL9syqzgeWxPRhMcr90TgVY7lIv=s64",
      "userId": "13932754754043581055"
     },
     "user_tz": -60
    },
    "id": "dM5g_tmMCc90"
   },
   "outputs": [],
   "source": [
    "def calculate_error(Y_pred,Y_test):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  res = [0]*6\n",
    "  for i in range(len(Y_pred)):\n",
    "    val = abs(Y_pred[i]-Y_test[i])\n",
    "    if val <= 0.05:\n",
    "      res[0]+=1\n",
    "    elif val <= 0.10:\n",
    "      res[1]+=1\n",
    "    elif val <= 0.20:\n",
    "      res[2]+=1\n",
    "    elif val <= 0.35:\n",
    "      res[3]+=1\n",
    "    elif val <= 0.50:\n",
    "      res[4]+=1\n",
    "    else:\n",
    "      res[5]+=1\n",
    "  return [x / len(Y_pred) for x in res]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57jX9-em_wHj"
   },
   "source": [
    "## Important points in the model:\n",
    "- In the convolution layer, we added the attribut padding In order not to downsize the image because we don't want to ignore the stones on the borders.\n",
    "- for the activation function in the output layer, we chose sigmoid function because it exists between (0 to 1) and it is especially used for models where we have to predict the probability as an output. So we think it is the best choice in our case since we have to predict the probability that black wins.\n",
    "- To avoid the overfitting we used the technique of dropout.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7225,
     "status": "ok",
     "timestamp": 1607077359609,
     "user": {
      "displayName": "Silmaril",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj25vLnfeosorL9syqzgeWxPRhMcr90TgVY7lIv=s64",
      "userId": "13932754754043581055"
     },
     "user_tz": -60
    },
    "id": "kPj5zOq7m7mZ",
    "outputId": "83c9ac7c-5612-40de-a70f-13bbb66e2533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 9, 9, 64)          4864      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 48)          27696     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 9, 9, 48)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 48)          192       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 48)          20784     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 9, 9, 48)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 9, 9, 48)          192       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3888)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              3982336   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 81)                83025     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 81)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 82        \n",
      "=================================================================\n",
      "Total params: 4,156,611\n",
      "Trainable params: 4,156,163\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "#if device_name != '/device:GPU:0':\n",
    "#  print('\\n\\nThis error most likely means that this notebook is not '\n",
    "#        'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "#        'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "#  raise SystemError('GPU device not found')\n",
    "#print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 1024\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(64, (5, 5), padding='same', activation = 'relu', data_format='channels_last', input_shape=(9,9,3)),\n",
    "    Dropout(rate=0.5),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), padding='same', activation = 'relu', data_format='channels_last'),\n",
    "    Dropout(rate=0.5),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(48, (3, 3), padding='same', activation = 'relu', data_format='channels_last'),\n",
    "    Dropout(rate=0.5),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(48, (3, 3), padding='same', activation = 'relu', data_format='channels_last'),\n",
    "    Dropout(rate=0.5),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(1024, activation = 'relu'),\n",
    "    Dropout(rate=0.5),\n",
    "    Dense(81, activation = 'relu'),\n",
    "    Dropout(rate=0.5),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2295094,
     "status": "ok",
     "timestamp": 1607079658396,
     "user": {
      "displayName": "Silmaril",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj25vLnfeosorL9syqzgeWxPRhMcr90TgVY7lIv=s64",
      "userId": "13932754754043581055"
     },
     "user_tz": -60
    },
    "id": "3oQojFD09kEm",
    "outputId": "ec555dcb-d3f1-4778-97e4-f17bddd8a0ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "325/325 [==============================] - 350s 1s/step - loss: 0.1089 - mse: 0.1089 - mae: 0.2630\n",
      "Epoch 2/200\n",
      "325/325 [==============================] - 325s 1s/step - loss: 0.0549 - mse: 0.0549 - mae: 0.1608\n",
      "Epoch 3/200\n",
      "325/325 [==============================] - 321s 988ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1436\n",
      "Epoch 4/200\n",
      "325/325 [==============================] - 319s 983ms/step - loss: 0.0425 - mse: 0.0425 - mae: 0.1355\n",
      "Epoch 5/200\n",
      "325/325 [==============================] - 321s 988ms/step - loss: 0.0408 - mse: 0.0408 - mae: 0.1318\n",
      "Epoch 6/200\n",
      "325/325 [==============================] - 316s 974ms/step - loss: 0.0393 - mse: 0.0393 - mae: 0.1284\n",
      "Epoch 7/200\n",
      "325/325 [==============================] - 319s 980ms/step - loss: 0.0386 - mse: 0.0386 - mae: 0.1267\n",
      "Epoch 8/200\n",
      "325/325 [==============================] - 318s 979ms/step - loss: 0.0374 - mse: 0.0374 - mae: 0.1243\n",
      "Epoch 9/200\n",
      "325/325 [==============================] - 317s 975ms/step - loss: 0.0367 - mse: 0.0367 - mae: 0.1229\n",
      "Epoch 10/200\n",
      "325/325 [==============================] - 317s 977ms/step - loss: 0.0365 - mse: 0.0365 - mae: 0.1219\n",
      "Epoch 11/200\n",
      "325/325 [==============================] - 318s 979ms/step - loss: 0.0360 - mse: 0.0360 - mae: 0.1210\n",
      "Epoch 12/200\n",
      "325/325 [==============================] - 319s 980ms/step - loss: 0.0355 - mse: 0.0355 - mae: 0.1199\n",
      "Epoch 13/200\n",
      "325/325 [==============================] - 317s 976ms/step - loss: 0.0354 - mse: 0.0354 - mae: 0.1192\n",
      "Epoch 14/200\n",
      "325/325 [==============================] - 318s 978ms/step - loss: 0.0349 - mse: 0.0349 - mae: 0.1183\n",
      "Epoch 15/200\n",
      "325/325 [==============================] - 321s 988ms/step - loss: 0.0343 - mse: 0.0343 - mae: 0.1169\n",
      "Epoch 16/200\n",
      "325/325 [==============================] - 322s 992ms/step - loss: 0.0341 - mse: 0.0341 - mae: 0.1167\n",
      "Epoch 17/200\n",
      "325/325 [==============================] - 320s 984ms/step - loss: 0.0338 - mse: 0.0338 - mae: 0.1159\n",
      "Epoch 18/200\n",
      "325/325 [==============================] - 334s 1s/step - loss: 0.0337 - mse: 0.0337 - mae: 0.1157\n",
      "Epoch 19/200\n",
      "265/325 [=======================>......] - ETA: 59s - loss: 0.0336 - mse: 0.0336 - mae: 0.1154 "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_data, Y_data, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6170,
     "status": "ok",
     "timestamp": 1607079735990,
     "user": {
      "displayName": "Silmaril",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj25vLnfeosorL9syqzgeWxPRhMcr90TgVY7lIv=s64",
      "userId": "13932754754043581055"
     },
     "user_tz": -60
    },
    "id": "9QOIvW90oPvq",
    "outputId": "693b95dd-3b20-4cc4-ce0a-baa3f25fbf92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "0.51\n",
      "0.20\n",
      "0.21\n",
      "0.07\n",
      "0.01\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "model.save('.')\n",
    "\n",
    "res = calculate_error(model.predict(X_test),Y_test)\n",
    "for i in range(6):\n",
    "  print(\"%.2f\" % (res[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQrLMuPBy7oF"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "#axes[0].title('mae')\n",
    "axes[0].plot(history.history['mae'], 'g')\n",
    "axes[0].plot(history.history['val_mae'], 'r')\n",
    "#axes[1].title('mse')\n",
    "axes[1].plot(history.history['mse'], 'g')\n",
    "axes[1].plot(history.history['val_mse'], 'r')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oGzjuj5m7md"
   },
   "source": [
    "# Last step\n",
    "\n",
    "Prepare your model to predict the set of new data to predict, you will have only 6 hours to push your predictions.\n",
    "\n",
    "(may be you would like to express, when guessing the percentage of wins for blacks, that it should reflect the fact that this score should be the same for all the symmetries you considered)...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eq_vUZurAbXW"
   },
   "outputs": [],
   "source": [
    "def get_raw_data_go_prediction():\n",
    "    ''' Returns the set of samples from the local file or download it if it does not exists'''\n",
    "    import gzip, os.path\n",
    "    import json\n",
    "\n",
    "    raw_samples_file = \"positions-to-evaluate-9x9-attempt.json.gz\"\n",
    "\n",
    "    if not os.path.isfile(raw_samples_file):\n",
    "        print(\"File\", raw_samples_file, \"not found, I am downloading it...\", end=\"\")\n",
    "        import urllib.request \n",
    "        urllib.request.urlretrieve (\"https://www.labri.fr/perso/lsimon/ia-inge2/positions-to-evaluate-9x9-attempt.json.gz\", raw_samples_file)\n",
    "        print(\" Done\")\n",
    "\n",
    "    with gzip.open(raw_samples_file) as fz:\n",
    "        data = json.loads(fz.read().decode(\"utf-8\"))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmyMPxWgAe9O"
   },
   "outputs": [],
   "source": [
    "def three_planes_encoder_prediction(data):\n",
    "    X = []\n",
    "\n",
    "    for i in range(len(data)): \n",
    "        black_stones = np.zeros((9,9), dtype=np.float32)\n",
    "        white_stones = np.zeros((9,9), dtype=np.float32)\n",
    "        player_turn = np.zeros((9,9), dtype=np.float32)\n",
    "        black = data[i][\"black_stones\"]\n",
    "        white = data[i][\"white_stones\"]\n",
    "        \n",
    "        for j in range(len(black)):\n",
    "            x,y = name_to_coord(black[j])\n",
    "            black_stones[x,y] = 1\n",
    "        for j in range(len(white)):\n",
    "            x,y = name_to_coord(white[j])\n",
    "            white_stones[x,y] = 1\n",
    "        if (len(data[i][\"list_of_moves\"])%2 == 0):\n",
    "          # black turn 1, white turn 0\n",
    "          player_turn = np.ones((9,9), dtype=np.float32)\n",
    "        img = np.dstack((black_stones,white_stones,player_turn))\n",
    "        X.append(img)\n",
    "        \n",
    "    X_data = np.array(X)\n",
    "    print(X_data.shape)\n",
    "    \n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7ye7F7SAh4_"
   },
   "outputs": [],
   "source": [
    "def create_result_file(newdata):\n",
    "    ''' Exemple de méthode permettant de générer le fichier de resultats demandés. '''\n",
    "    y_predicted = model.predict(newdata)\n",
    "    with open(\"my_predictions.txt\", \"w\") as f:\n",
    "         for i in range(len(y_predicted)):\n",
    "           #print(y_predicted[i][0])\n",
    "           p = round(y_predicted[i][0],2)\n",
    "           f.write(str(p)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkEUxwrlAiXk"
   },
   "outputs": [],
   "source": [
    "#data_to_predict = get_raw_data_go_prediction()\n",
    "#x_to_predict = three_planes_encoder_prediction(data_to_predict)\n",
    "#x_to_predict = x_to_predict.astype('float32')\n",
    "#create_result_file(x_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTdhkfxImjHb"
   },
   "outputs": [],
   "source": [
    "#file1 = open('/content/positions-to-evaluate-9x9-attempt.results.txt', 'r') \n",
    "#reel_values = file1.readlines() \n",
    "\n",
    "#file2 = open('/content/my_predictions.txt', 'r') \n",
    "#predicted_values = file2.readlines() \n",
    "\n",
    "#for i in range (len(reel_values)):\n",
    "  #reel_value = float(predicted_values[i].strip())\n",
    "  #predicted_value = float(reel_values[i].strip())\n",
    "  #print(round(abs(predicted_value - reel_value),2)) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tp-ml-go-latest.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
